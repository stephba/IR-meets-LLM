{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup generative model (open/closed model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, OPTForCausalLM\n",
    "\n",
    "class GenerativeModel:\n",
    "    def __init__(self, max_length) -> None:\n",
    "        self.model = OPTForCausalLM.from_pretrained(\"facebook/opt-1.3b\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-1.3b\")\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def get_open_model_answer(self, question, context):\n",
    "        prompt = f\"CONTEXT:\\n{context}\\nQUESTION:\\n{question}\"\n",
    "        # generate answer\n",
    "        answer = self.generate_answer(prompt)\n",
    "        # remove prompt from generated text\n",
    "        answer = answer.removeprefix(prompt)\n",
    "        return answer\n",
    "\n",
    "    def get_closed_model_answer(self, question):\n",
    "        prompt = question\n",
    "        # generate answer\n",
    "        answer = self.generate_answer(prompt)\n",
    "        # remove prompt from generated text\n",
    "        answer = answer.removeprefix(prompt)\n",
    "        return answer\n",
    "    \n",
    "    def generate_answer(self, prompt):\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "        generate_ids = self.model.generate(inputs.input_ids, max_length=self.max_length)\n",
    "        return self.tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_model = GenerativeModel(max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Austria is a landlocked country of approximately 8.95 million inhabitants in Central Europe. It is bordered by the Czech Republic and Germany to the north, Slovakia and Hungary to the east, Slovenia and Italy to the south, and Switzerland and Liechtenstein to the west.\"\n",
    "question = \"Where is Austria?\"\n",
    "\n",
    "print(generative_model.get_open_model_answer(question, context))\n",
    "print(generative_model.get_closed_model_answer(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
